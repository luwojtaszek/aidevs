Generatywna Sztuczna Inteligencja to obszar Sztucznej Inteligencji, skupiajÄ…cy siÄ™ na generowaniu np. tekstu, kodu, obrazÃ³w czy filmÃ³w. Trenowana na duÅ¼ych zestawach danych, jest zdolna do tworzenia nowych treÅ›ci. W rezultacie, Generatywna AI (GenAI) moÅ¼e odgrywaÄ‡ ogromnÄ… rolÄ™ w procesach kreatywnych, w tym takÅ¼e w rozwijaniu oprogramowania. Obecnie jednym z najpopularniejszych przykÅ‚adÃ³w takich narzÄ™dzi sÄ… DuÅ¼e Modele JÄ™zykowe (Large Language Models, LLM), takie jak rodzina modeli GPT od firmy OpenAI, na ktÃ³rej skupimy naszÄ… uwagÄ™ w nadchodzÄ…cych tygodniach.

W zwiÄ…zku z tym, Å¼e rozwÃ³j umiejÄ™tnoÅ›ci zwiÄ…zanych z wykorzystaniem LLM jest znacznie prostszy niÅ¼ nauka programowania, juÅ¼ na starcie masz ogromnÄ… przewagÄ™. Co podkreÅ›la [cytat Grega Brockmana, wspÃ³Å‚zaÅ‚oÅ¼yciela OpenAI](https://twitter.com/gdb/status/1692699977628242279).

![](https://assets.circle.so/vvpm7yzgcz7qr2n8a6bw11jrp16h)

Jego stwierdzenie, Å¼e to osoby potrafiÄ…ce programowaÄ‡ mogÄ… mieÄ‡ najwiÄ™kszy wpÅ‚yw na AI, jest bardzo widoczne w praktyce. Jak niebawem siÄ™ przekonasz, **poÅ‚Ä…czenie duÅ¼ych modeli jÄ™zykowych z kodem, pozwoli Ci adresowaÄ‡ obecne ograniczenia modeli oraz poÅ‚Ä…czyÄ‡ je z zewnÄ™trznymi usÅ‚ugami, znacznie rozszerzajÄ…c dostÄ™pne moÅ¼liwoÅ›ci.** WczeÅ›niej jednak konieczne jest zrozumienie technologii, narzÄ™dzi oraz technik pracy, ktÃ³re pozwolÄ… Ci wyjÅ›Ä‡ znacznie dalej niÅ¼ rozmowa z ChatGPT. Z tego powodu niemal caÅ‚kowicie pominiemy zarÃ³wno ChatGPT, jak i narzÄ™dzia wspierajÄ…ce kodowanie (np. GitHub Copilot czy [Cursor.sh](https://www.cursor.sh/), choÄ‡ bardzo je polecamy). W zamian **skupimy siÄ™ na bezpoÅ›redniej integracji OpenAI API z kodem aplikacji oraz dodatkiem w postaci automatyzacji**.

## Obecne moÅ¼liwoÅ›ci DuÅ¼ych Modeli JÄ™zykowych

Modele JÄ™zykowe projektowane sÄ… z myÅ›lÄ…Â o tworzeniu treÅ›ci na podstawie wejÅ›ciowych danych oraz podÄ…Å¼aniem za instrukcjami (zwykle) w kontekÅ›cie czatu. W wyniku (prawdopodobnie) ogromnej skali danych wykorzystywanych do trenowania duÅ¼ych modeli jÄ™zykowych, mamy do czynienia ze zjawiskiem tzw. **emergencji** zwiÄ…zanym z [pojawianiem siÄ™ zachowaÅ„Â nieobecnych w przypadku mniejszych modeli](https://arxiv.org/abs/2206.07682). PrzykÅ‚adem moÅ¼e byÄ‡Â zdolnoÅ›Ä‡ do tÅ‚umaczeÅ„ z jednego jÄ™zyka na inny, pomimo tego, Å¼e model nie byÅ‚Â dokÅ‚adnie do tego trenowany (ale oczywiÅ›cie miaÅ‚Â kontakt z tymi jÄ™zykami).

ObecnoÅ›Ä‡ emergencji w LLM moÅ¼e wyraÅºnie sugerowaÄ‡, Å¼e **wszystkie moÅ¼liwoÅ›ci modeli, z ktÃ³rymi obecnie mamy do czynienia, nie sÄ… nam jeszcze znane**. Tym bardziej Å¼e mÃ³wimy tutaj o zachowaniach, ktÃ³re mogÄ… zaskakiwaÄ‡ takÅ¼e twÃ³rcÃ³w OpenAI. PrzykÅ‚adem jest fragment [GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf), omawiajÄ…cy **nieoczekiwany wzrost skutecznoÅ›ci w zadaniach "Hindsight Neglect"** zwiÄ…zanych z odrÃ³Å¼nianiem przewidywania od faktycznej odpowiedzi w obliczu znajomoÅ›ci rezultatu.

![](https://assets.circle.so/u36l72lofxoe6qej6aufrocb24m0)

  
To jednak nie oznacza, Å¼e nie znamy zastosowaÅ„ duÅ¼ych modeli jÄ™zykowych oraz scenariuszy, w ktÃ³rych sprawdzajÄ… siÄ™ one wprost genialnie. Oto kilka przykÅ‚adÃ³w:

*   **Wcielanie siÄ™ w rÃ³Å¼ne role niczym kameleon**, co jednoczeÅ›nie nadaje kontekst interakcji, dziÄ™ki ktÃ³remu uwaga modelu skupia siÄ™ na wybranym zagadnieniu (np. definicje wystÄ™pujÄ…ce w rÃ³Å¼nych dziedzinach sÄ… dziÄ™ki okreÅ›leniu roli asystenta postrzegane jednoznacznie).
    
*   **Transformacje dostarczonych treÅ›ci**, np. tÅ‚umaczenia, korekty, analizy i podsumowania, uwzglÄ™dniajÄ…ce kontekst przetwarzanych dokumentÃ³w. Warto podkreÅ›liÄ‡, Å¼e LLM obecnie sÄ…Â znacznie lepsze w **transformacji istniejÄ…cej treÅ›ci niÅ¼ jej generowaniu, nawet jeÅ›li ta treÅ›Ä‡ zostaÅ‚a rÃ³wnieÅ¼ wygenerowana przez LLM**
    
*   **Parsowanie danych,** uwzglÄ™dniajÄ…c zadania, ktÃ³re sÄ… bardzo trudne do zrealizowania programistycznie, np. za pomocÄ… wyraÅ¼eÅ„ regularnych. Np. pracÄ™ z rÃ³Å¼nymi jÄ™zykami rÃ³wnolegle.
    
*   **Odpowiadanie na pytania i generowanie treÅ›ci** na podstawie danych przekazanych jako kontekst zapytania, czyli tzw. Retrieval-Augmented Generation o ktÃ³rym bÄ™dziemy jeszcze mÃ³wiÄ‡.
    
*   **Zadania zwiÄ…zane z programowaniem** uwzglÄ™dniajÄ… tworzenie, modyfikowanie, wyjaÅ›nianie, oraz debugowanie kodu (tutaj pomocne sÄ…Â takÅ¼e modele â€œVisionâ€ umoÅ¼liwiajÄ…ce pracÄ™Â z obrazami).
    
*   **Integracja z kodem aplikacji** i zastosowanie biznesowe czyniÄ… LLM uÅ¼ytecznymi narzÄ™dziami, ktÃ³re pozwalajÄ… realizowaÄ‡ zadania zwiÄ…zane z przetwarzaniem jÄ™zyka naturalnego (eng. Natural Language Processing, NLP).
    
*   **PosÅ‚ugiwanie siÄ™ API**, w szczegÃ³lnoÅ›ci w kontekÅ›cie [Function Calling](https://openai.com/blog/function-calling-and-other-api-updates), oraz wersji modeli OpenAI wyspecjalizowanych w wyborze funkcji i generowaniu do nich parametrÃ³w.
    

Obecnie, ze wzglÄ™du na ograniczenia modeli, o ktÃ³rych powiemy za chwilÄ™, znacznie lepsze rezultaty otrzymamy w przypadku zadaÅ„ realizowanych **na podstawie dostarczonego kontekstu** i istniejÄ…cych danych. PrzykÅ‚adowo, zamiast oczekiwaÄ‡, Å¼e GPT-4 napisze dla mnie tekst, ktÃ³ry wÅ‚aÅ›nie czytasz, wykorzystujÄ™ go jedynie w celu korekty wybranych fragmentÃ³w tego, co juÅ¼ napisaÅ‚em.

Podobnie wyglÄ…da to takÅ¼e w przypadku odpowiedzi na pytania, ktÃ³rych jakoÅ›Ä‡ jest **nieporÃ³wnywalnie lepsza**, gdy dotyczÄ… one treÅ›ci doÅ‚Ä…czonych do zapytania, niÅ¼ gdy odpowiedÅº generowana jest wyÅ‚Ä…cznie na podstawie bazowej wiedzy modelu, ktÃ³ra obecnie czÄ™sto bywa nieaktualna.

Ostatecznie prawdopodobnie najwaÅ¼niejszÄ… z umiejÄ™tnoÅ›ci DuÅ¼ych Modeli JÄ™zykowych jest posÅ‚ugiwanie siÄ™ zewnÄ™trznymi usÅ‚ugami, narzÄ™dziami czy urzÄ…dzeniami. W praktyce mÃ³wimy tutaj o **generowaniu obiektÃ³w JSON**, ktÃ³re programistycznie sÄ… przesyÅ‚ane jako payload zapytania HTTP. NiemaÅ‚Ä… rolÄ™ odgrywa takÅ¼e zdolnoÅ›Ä‡ do **podejmowania decyzji na temat tego, ktÃ³rÄ… z funkcji naleÅ¼y uruchomiÄ‡**, a nawet **planowania realizacji zadania, z uwzglÄ™dnieniem dostÄ™pnych narzÄ™dzi**. WÃ³wczas dochodzimy do koncepcji tzw. "Agenta" zdolnego do **autonomicznego (lub czÄ™Å›ciowo autonomicznego) realizowania zadaÅ„**, czego przykÅ‚adem jest, chociaÅ¼by [projekt Devin](https://www.cognition-labs.com/blog).

PeÅ‚ne wykorzystanie tego, co oferujÄ… LLM-y, wymaga **poÅ‚Ä…czenia ich z kodem aplikacji**. Nie mÃ³wimy tutaj jedynie o poÅ‚Ä…czeniu z API OpenAI czy modelami OpenSource (np. Mixtral 8Ã—7b). Do gry wchodzi tutaj projektowanie caÅ‚ej interakcji, uwzglÄ™dniajÄ…cej miÄ™dzy innymi:

*   **przetwarzanie rÃ³Å¼nych formatÃ³w danych** i ich organizacjÄ™ na potrzeby LLM (np. podziaÅ‚ na mniejsze fragmenty, wzbogacanie, opisywanie, kompresja)
    
*   **wykorzystywanie dynamicznego kontekstu** (eng. [Retrieval Augmented Generation](https://research.ibm.com/blog/retrieval-augmented-generation-RAG), RAG) oraz dÅ‚ugoterminowej pamiÄ™ci dziÄ™ki poÅ‚Ä…czeniu baz wektorowych (Qdrant / Supabase) oraz klasycznych silnikÃ³w wyszukiwania (Algolia / ElasticSearch). PrzykÅ‚adem moÅ¼e byÄ‡ [Quivr](https://github.com/stangirard/quivr).
    
*   **projektowanie zÅ‚oÅ¼onych interakcji** wykraczajÄ…cych poza pojedyncze zapytania do modelu (np. w modelu [ReAct](https://react-lm.github.io/)), uwzglÄ™dniajÄ…cych korzystanie z rÃ³Å¼nych narzÄ™dzi.
    
*   **Å‚Ä…czenie ze sobÄ… wielu modeli** wyspecjalizowanych w realizowaniu konkretnych zadaÅ„ (np. przetwarzaniu lub generowaniu grafik, audio czy wideo). PrzykÅ‚adem mogÄ… byÄ‡ usÅ‚ugi takie jak [ElevenLabs](https://www.elevenlabs.io/) czy [Replicate](https://replicate.com/).
    
*   **trenowanie, Å‚Ä…czenie (merge) i fine-tuning modeli** w celu zaadresowania konkretnych rodzajÃ³w zadaÅ„ i sposobÃ³w ich wykonania, oraz ogÃ³lnego zwiÄ™kszenia skutecznoÅ›ci modelu w wybranych obszarach.
    

Projektowanie takich aplikacji wymaga takÅ¼e podejmowania szeregu dodatkowych zadaÅ„ zwiÄ…zanych z **monitorowaniem, moderacjÄ…, testowaniem i optymalizacjÄ…** systemu. MajÄ…c na uwadze to wszystko, zrozumiaÅ‚a powinna byÄ‡ teraz perspektywa Grega Brockmana, mÃ³wiÄ…ca o roli osÃ³b potrafiÄ…cych programowaÄ‡. Zdobycie programistycznych umiejÄ™tnoÅ›ci umoÅ¼liwiajÄ…cych wykorzystywanie duÅ¼ych modeli jÄ™zykowych jest nieporÃ³wnywalnie trudniejsze od jedynie rozszerzenia swojej wiedzy o techniki pracy z nimi.

## Obecne ograniczenia DuÅ¼ych Modeli JÄ™zykowych

Trenowanie LLM jest czasochÅ‚onne i wymaga przygotowania duÅ¼ych zestawÃ³w danych. To z tego powodu bazowa wiedza modeli OpenAI ma swÃ³j ograniczony zasiÄ™g czasowy (dla GPT-3.5-turbo w chwili pisania tych sÅ‚Ã³w jest to wrzesieÅ„ 2021, a dla GPT-4-turbo to grudzieÅ„ 2023). Dodatkowo sama charakterystyka modeli wiÄ…Å¼e siÄ™ z rÃ³Å¼nego rodzaju ograniczeniami, ktÃ³re po czÄ™Å›ci moÅ¼emy adresowaÄ‡ lub omijaÄ‡, a na inne nie mamy odpowiedzi.

> âš ï¸ PoniÅ¼sze przykÅ‚ady pochodzÄ… z narzÄ™dzia Playground, ktÃ³re omÃ³wimy bardziej szczegÃ³Å‚owo w kolejnych lekcjach. JeÅ›li chcesz skorzystaÄ‡ z niego juÅ¼ teraz, upewnij siÄ™, Å¼e jesteÅ› w trybie "Chat" i aktywny model to GPT-4.

  

[02.mp4](https://assets.circle.so/dts791rcqyyr1jjrewk23owshgq0)

  

**Ograniczenie bazowej wiedzy i halucynacje**

Brak dostÄ™pu do dowolnej wiedzy jest jednym z najwiÄ™kszych ograniczeÅ„ LLM, ktÃ³re wydaje siÄ™ wykluczaÄ‡ je z zastosowania np. podczas pracy z nowymi narzÄ™dziami, na temat ktÃ³rych model nie ma pojÄ™cia. Jest to jedna z gÅ‚Ã³wnych przyczyn tzw. **halucynacji modelu**, w wyniku ktÃ³rej odpowiedzi nie tylko nie zawierajÄ… poprawnych informacji, ale wyglÄ…dajÄ… tak, jakby byÅ‚y poprawne, przez co trudno na pierwszy rzut oka je zauwaÅ¼yÄ‡. PrzykÅ‚adowo, wedÅ‚ug GPT-4 najnowsza wersja macOS to Monterey (aczkolwiek taka odpowiedÅº nie zawsze siÄ™ pojawi, o czym powiem za chwilÄ™, omawiajÄ…c niedeterministycznÄ… naturÄ™ modeli).

![](https://assets.circle.so/36dnh7tzp0ypyuupohzxmen4d2j0)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/ygwvpyvpS61L6l7qdFvxqdBa?model=gpt-4&mode=chat)

IstniejÄ… rÃ³Å¼ne sposoby na zmniejszenie ryzyka takich sytuacji. Jednym z nich jest modyfikacja promptu (instrukcji dla modelu), aby podkreÅ›laÅ‚a prawdomÃ³wnoÅ›Ä‡ oraz bezpoÅ›rednie informowanie o braku dostÄ™pnej wiedzy.

![](https://assets.circle.so/wxha20a5noc9f7y05okz45j9mzvu)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/EbzMyCreijOAwU6WpXKVkoHH?model=gpt-4&mode=chat)

Do realizacji niektÃ³rych zadaÅ„ mamy moÅ¼liwoÅ›Ä‡ **dostarczenia dodatkowej wiedzy do modelu w postaci kontekstu zapytania.** JeÅ¼eli tylko jest to moÅ¼liwe, warto to zrobiÄ‡ oraz dodatkowo podkreÅ›liÄ‡, Å¼e generowane odpowiedzi muszÄ… wykorzystywaÄ‡ wiedzÄ™ z kontekstu. WÃ³wczas np. nasze pytanie o wersjÄ™ systemu jest poprawne, poniewaÅ¼ powiÄ…zana z nim informacja zostaÅ‚a doÅ‚Ä…czona do zapytania.

![](https://assets.circle.so/gchu8hbxph8oblx6kc65d4vsdhvk)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/TktWqRIyaqDdhqKM2kN2VjGV?model=gpt-4&mode=chat)

Poza informacjÄ… o najnowszej wersji systemu doÅ‚Ä…czyÅ‚em takÅ¼e aktualnÄ… datÄ™. ZrobiÅ‚em to nie bez powodu, poniewaÅ¼ podstawowa wersja modelu GPT-4 nie wie nawet "kiedy jest dziÅ›", o ile nie doÅ‚Ä…czymy tej informacji do kontekstu. JednoczeÅ›nie widzisz juÅ¼, Å¼e model Å›wietnie radzi sobie z **wykorzystywaniem informacji zawartych w kontekÅ›cie**, co otwiera przed nami rÃ³Å¼ne moÅ¼liwoÅ›ci oraz jasno sugeruje, Å¼e **poza bazowÄ… wiedzÄ… modelu, szczegÃ³lnie waÅ¼ne sÄ… takÅ¼e jego umiejÄ™tnoÅ›ci zwiÄ…zane z rozumowaniem, przetwarzaniem oraz transformacjÄ… treÅ›ci**.

**Ograniczenie dÅ‚ugoÅ›ci kontekstu**

Obecne LLM opierajÄ… siÄ™ na architekturze modelu Transformer, zaprezentowanej po raz pierwszy przez Google w 2017 roku w publikacji [Attention Is All You Need](https://arxiv.org/abs/1706.03762). WiÄ…Å¼e siÄ™ z niÄ… zarÃ³wno szereg moÅ¼liwoÅ›ci, jak i ograniczeÅ„. Jednym z nich jest limit dÅ‚ugoÅ›ci treÅ›ci przetwarzanej w danej chwili, obejmujÄ…cy zarÃ³wno **dane wejÅ›ciowe, jak i te generowane przez model**, ktÃ³ry okreÅ›la siÄ™ jako tzw. "Token Window".

![](https://assets.circle.so/dgj0dz3sux6s263orz4kujusegg0)

Limity rÃ³Å¼niÄ… siÄ™ w zaleÅ¼noÅ›ci od modeli. Obecnie mÃ³wimy w przypadku modeli od OpenAI o zakresie pomiÄ™dzy okoÅ‚o 4 a 128 tys. tokenÃ³w (fragmentÃ³w sÅ‚Ã³w). SÄ… jednak wyjÄ…tki w postaci np. modelu [Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/), ktÃ³ry jest zdolny do pracy na 1 milionie tokenÃ³w w ramach pojedynczego zapytania, uwzglÄ™dniajÄ…c przy tym obrazy, a takÅ¼e materiaÅ‚y wideo.

Z dÅ‚ugoÅ›ciÄ… kontekstu wiÄ…Å¼Ä… siÄ™ jeszcze trzy dodatkowe wyzwania, z ktÃ³rymi bÄ™dziesz siÄ™ mierzyÄ‡ podczas pracy z duÅ¼ymi modelami jÄ™zykowymi. SÄ… to:

*   **Koszty** zwiÄ…zane z przetwarzaniem i generowaniem tokenÃ³w, ktÃ³re szybko rosnÄ…, nawet na stosunkowo maÅ‚ej skali.
    
*   **WydajnoÅ›Ä‡**, ktÃ³ra w duÅ¼ym stopniu jest uzaleÅ¼niona od liczby tokenÃ³w generowanych w ramach zapytania (zmienia siÄ™ to w przypadku platformy [https://groq.com](https://groq.com/), ktÃ³ra obecnie wspiera tylko wybrane modele Open Source).
    
*   **SkutecznoÅ›Ä‡**, ktÃ³ra wedÅ‚ug publikacji [Lost In The Middle](https://arxiv.org/pdf/2307.03172.pdf), spada w przypadku jednorazowego przetwarzania dÅ‚uÅ¼szych treÅ›ci, ale problem ten wydaje siÄ™ w duÅ¼ym stopniu rozwiÄ…zany w nowych modelach takich jak Claude 3 Opus czy nawet w wersji 2.1 z zastosowaniem [odpowiedniego promptu](https://www.anthropic.com/news/claude-2-1-prompting).
    

![](https://assets.circle.so/mlxbm610rsz9rsqkjaxz2ax3jgrl)

Wszystko to prowadzi nas do prostego wniosku, mÃ³wiÄ…cego o tym, Å¼e warto projektowaÄ‡ swoje systemy tak, aby pracowaÅ‚y na moÅ¼liwie maÅ‚ym zestawie informacji **istotnych dla bieÅ¼Ä…cego zadania**. PrzykÅ‚ad poniÅ¼ej pokazuje, jak nieprawidÅ‚owe dobranie kontekstu sprawiÅ‚o, Å¼e model nie byÅ‚ w stanie udzieliÄ‡ poprawnej odpowiedzi na pytanie (ale jego zachowanie jest zgodne z instrukcjÄ…).

![](https://assets.circle.so/0rhnw91sywyxlk259zjxgqhnap8t)

ğŸ”—[Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/csXdIoK1BetYGtvljtEAtFr7?model=gpt-4&mode=chat)

WÄ…tek pracy z tokenami i dÅ‚ugim kontekstem (np. prowadzeniem dÅ‚ugich rozmÃ³w czy przetwarzaniem dÅ‚ugich dokumentÃ³w) bÄ™dziemy jeszcze poruszaÄ‡ wielokrotnie w kolejnych lekcjach.Â Na razie zapamiÄ™taj jedynie, Å¼e zwykle **warto utrzymywaÄ‡ kontekst tak krÃ³tkim, jak to moÅ¼liwe**, o ile nie tracimy jego sensu.

**Niedeterministyczna natura**

Do prezentowanych przykÅ‚adÃ³w zadaÅ„ realizowanych przez GPT-4 doÅ‚Ä…czam linki kierujÄ…ce do Playground. JeÅ›li z nich skorzystasz, to prawdopodobnie zauwaÅ¼ysz, Å¼e przy **ponownych prÃ³bach wykonywania dokÅ‚adnie tych samych instrukcji, wynik moÅ¼e ulegaÄ‡ zmianie**. Powodem jest **niedeterministyczna natura modeli**, ktÃ³ra w przeciwieÅ„stwie do **Pure Function** znanych z programowania funkcyjnego, nie daje nam pewnoÅ›ci, Å¼e dla tych samych danych uzyskamy dokÅ‚adnie takÄ… samÄ…Â odpowiedÅº. Od jakiegoÅ›Â czasu OpenAI udostÄ™pnia jednak parametr "seed", ktÃ³ry pozwala na otrzymanie tych samych rezultatÃ³w, ale znajduje siÄ™Â on w "wersji beta" od czasu premiery.

W kolejnej lekcji wyjaÅ›niÄ™, z czego to dokÅ‚adnie wynika. Tymczasem sprÃ³buj przejÅ›Ä‡ do poniÅ¼szego przykÅ‚adu i wykonaÄ‡ go kilkukrotnie (kasujÄ…c wiadomoÅ›Ä‡ wygenerowanÄ… przez asystenta). WÃ³wczas zauwaÅ¼ysz, Å¼e co jakiÅ› czas generowana odpowiedÅº bÄ™dzie rÃ³Å¼niÄ‡ siÄ™ od wczeÅ›niejszych.

![](https://assets.circle.so/3v4rjhf6vqidbeqeaa1how24ykkx)

  

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/NIf99Z2wfcCGFDnqdgsXK6Av?model=gpt-4&mode=chat)

Takie zachowanie jest bardzo niepoÅ¼Ä…dane w przypadku logiki aplikacji realizujÄ…cej okreÅ›lone zadania. Dodatkowe wyzwania pojawiajÄ… siÄ™ takÅ¼e na etapie wprowadzania modyfikacji do promptÃ³w oraz trudnych do przewidzenia danych wejÅ›ciowych (np. w przypadku czatbotÃ³w nie moÅ¼emy przewidzieÄ‡ tego, co wpisze uÅ¼ytkownik). Strategie radzenia sobie z tym problemem omÃ³wimy w pÃ³Åºniejszej czÄ™Å›ci AI\_Devs. Do tego czasu zapamiÄ™taj, Å¼e **moÅ¼esz jedynie sterowaÄ‡ zachowaniem modelu, ale nie masz pewnoÅ›ci, Å¼e wygenerowany rezultat zawsze bÄ™dzie zgodny z Twoimi zaÅ‚oÅ¼eniami**.

**Obliczenia i zadania logiczne**

Nowsze wersje modeli (np. GPT-4) [sÄ… coraz lepsze w zadaniach zwiÄ…zanych z obliczeniami oraz zÅ‚oÅ¼onymi zadaniami logicznymi](https://openai.com/research/improving-mathematical-reasoning-with-process-supervision). MajÄ…c jednak na uwadze ich niedeterministycznÄ… naturÄ™ oraz problemy zwiÄ…zane z halucynacjÄ…, raczej kiepskim pomysÅ‚em jest wykorzystywanie ich do przeprowadzania istotnych obliczeÅ„, szczegÃ³lnie na duÅ¼ych liczbach. Dlatego, jak widaÄ‡, GPT-4 podaje caÅ‚kowicie bÅ‚Ä™dny wynik dla zapytania: "821^5".

![](https://assets.circle.so/t9qmwb4zbh7iowm9ilpzb61v7w8n)

ğŸ”— [Zobacz przykÅ‚ad](https://platform.openai.com/playground/p/5eCXCJCRSLxeWP9wdbmiYN8z?model=gpt-4&mode=chat)

To jest przykÅ‚ad zadania, dla ktÃ³rego modele jÄ™zykowe po prostu **nie zostaÅ‚y stworzone**. Podobne problemy zaobserwujemy takÅ¼e przy przeliczaniu dat (np. GPT-4 nie zawsze wie, kiedy jest "za dwa tygodnie w Å›rodÄ™"), co nierzadko przydaje siÄ™ w praktycznych zastosowaniach LLM. Najlepszym sposobem na radzenie sobie w takich sytuacjach jest skorzystanie z narzÄ™dzi, ktÃ³re zostaÅ‚y stworzone z myÅ›lÄ… o takich zadaniach. PrzykÅ‚adem moÅ¼e byÄ‡ model WolframAlpha, ktÃ³ry bez najmniejszego problemu udziela poprawnej odpowiedzi na praktycznie dowolne obliczenia.

![](https://assets.circle.so/y30oyhbf6yg70np7adxzyksc7j44)

WspomniaÅ‚em juÅ¼, Å¼e GPT-4 jest zdolne do posÅ‚ugiwania siÄ™Â API poprzez generowanie obiektÃ³w JSON. W przypadku Wolfram Alpha bezpÅ‚atny plan umoÅ¼liwia wykonanie 2000 zapytaÅ„ miesiÄ™cznie (co nierzadko wystarcza do prywatnych zastosowaÅ„) w ramach dostÄ™pu do API. MoÅ¼emy wiÄ™c stworzyÄ‡ prompt, ktÃ³rego zadaniem bÄ™dzie **przeanalizowanie zapytania uÅ¼ytkownika i pobranie z niego informacji na temat zadania, ktÃ³re zostanie zrealizowane przez inny model**. ZwrÃ³cona odpowiedÅº moÅ¼e albo zostaÄ‡ bezpoÅ›rednio zwrÃ³cona uÅ¼ytkownikowi albo **sparafrazowana w czytelny sposÃ³b**. DokÅ‚adnie na tej samej zasadzie moÅ¼emy wyposaÅ¼yÄ‡ GPT-4 w inne narzÄ™dzia, ktÃ³re bÄ™dÄ… w stanie adresowaÄ‡ jego sÅ‚abe strony. O konkretach pomÃ³wimy jednak przy okazji lekcji na temat Function Calling.

## Praktyczne zastosowanie LLM w kontekÅ›cie prywatnym

WymieniaÅ‚em ogÃ³lne zastosowania DuÅ¼ych Modeli JÄ™zykowych, jednak moÅ¼e nie byÄ‡ jasne, jak przekÅ‚adajÄ… siÄ™ one na faktyczne zastosowanie w codziennym Å¼yciu. PominÄ™ jednak te najbardziej oczywiste przykÅ‚ady, ktÃ³re na co dzieÅ„ widzimy w Internecie, i skupiÄ™ siÄ™ na tych, ktÃ³re jednoznacznie wynikajÄ… z **poÅ‚Ä…czenia programowania z AI**.

### BezpoÅ›rednia integracja komputera i API

StaÅ‚y dostÄ™p do moÅ¼liwoÅ›ci oferowanych przez LLMy, a takÅ¼e przypisanie skrÃ³tÃ³w klawiszowych do wybranych zadaÅ„, pozwala znacznie przyspieszyÄ‡ pracÄ™. Zintegrowanie, na przykÅ‚ad GPT-4, opiera siÄ™ na poÅ‚Ä…czeniu z OpenAI API, ktÃ³re moÅ¼e byÄ‡ realizowane poprzez aplikacje takie jak: **Keyboard Maestro lub Shortcuts (macOS), AutoHotkey (Windows) oraz rozwijana przeze mnie publiczna wersja aplikacji Alice (macOS / Windows).** Alternatywnie, moÅ¼na skorzystaÄ‡ z ulubionego komunikatora (np. Slack / Telegram / Discord) i zbudowaÄ‡ prostego bota umoÅ¼liwiajÄ…cego rozmowÄ™ z modelami GPT.

![](https://assets.circle.so/epz233lca8xzdqhzmj1w1i5bg8t8)

WartoÅ›Ä‡ takiej integracji charakteryzuje siÄ™ tym, Å¼e roÅ›nie z czasem. Nie mÃ³wimy tutaj wyÅ‚Ä…cznie o prostych zapytaniach kierowanych do OpenAI, ale o uwzglÄ™dnieniu wÅ‚asnych rozszerzeÅ„, ktÃ³re zwiÄ™kszajÄ… moÅ¼liwoÅ›ci modelu oraz dopasowujÄ… go do naszych potrzeb. Widoczny na powyÅ¼szej animacji prosty przykÅ‚ad tÅ‚umaczeÅ„, moÅ¼e zostaÄ‡ dopasowany tak, aby utrzymywaÅ‚ ton charakterystyczny dla naszego stylu wypowiedzi. Daje to modelowi znacznie wiÄ™kszÄ… przewagÄ™ nad korzystaniem z narzÄ™dzi takich jak Deepl, a takÅ¼e pozwala na uzupeÅ‚nianie naszych wypowiedzi, wzbogacajÄ…c je lub upraszczajÄ…c.

Drugim zastosowaniem wÅ‚asnej integracji z LLM jest API, dziÄ™ki ktÃ³remu moÅ¼emy na przykÅ‚ad dodawaÄ‡ rÃ³Å¼ne informacje do pamiÄ™ci dÅ‚ugoterminowej. Jeden z przykÅ‚adÃ³w umoÅ¼liwia czytanie i zapamiÄ™tywanie treÅ›ci stron dodanych do tablicy Feedly, ktÃ³re nastÄ™pnie mogÄ… byÄ‡ wykorzystane w trakcie rozmowy z asystentem AI.

![](https://assets.circle.so/d4zaif7v1qt247x96mluqf8d0bfm)

### PoÅ‚Ä…czenie z Internetem i Wyszukiwarkami

GPT-4 domyÅ›lnie nie posiada dostÄ™pu do Internetu. NarzÄ™dzia takie jak Bing Chat czy Perplexity to oferujÄ…, jednak nie mamy wiÄ™kszego wpÅ‚ywu na sposÃ³b przetwarzania treÅ›ci oraz dostÄ™pu do informacji. Stworzenie wÅ‚asnej, prostej integracji, ktÃ³ra pozwala na wyszukiwanie oraz czytanie treÅ›ci stron, jest stosunkowo Å‚atwe dziÄ™ki LangChain oraz poÅ‚Ä…czeniu z Puppeteer czy Playwright. DostÄ™p do wynikÃ³w wyszukiwania moÅ¼emy uzyskaÄ‡ poprzez [SerpAPI](https://serpapi.com/) lub prosty skrypt dziaÅ‚ajÄ…cy na przykÅ‚ad w poÅ‚Ä…czeniu z DuckDuckGo.

![](https://assets.circle.so/5kfqk8kws6v0vugiockinbzzuwd4)

Efekt pozornie niewiele rÃ³Å¼ni siÄ™ od tego, ktÃ³ry moÅ¼emy osiÄ…gnÄ…Ä‡ na przykÅ‚ad w ChatBing. Jednak w praktyce daje nam to szereg przewag, takich jak:

*   CaÅ‚kowita kontrola nad promptami odpowiedzialnymi za przetwarzanie caÅ‚ej treÅ›ci strony lub jej wybranych fragmentÃ³w
    
*   MoÅ¼liwoÅ›Ä‡ zapisania historii konwersacji w celu jej wyszukiwania podczas przyszÅ‚ych rozmÃ³w
    
*   Zestawianie tych informacji z wÅ‚asnÄ… bazÄ… wiedzy, co prezentuje przykÅ‚ad poniÅ¼ej
    

![](https://assets.circle.so/wpnkb7gqog3ojl0osk79ncpx4fc5)

  
Podobne rezultaty osiÄ…gniemy w ostatnim module naszego programu, w ktÃ³rym zaprojektujemy mechaniki osobistego asystenta. JeÅ¼eli nie planujesz budowaÄ‡ takich integracji, to wspomniane Perplexity jest obecnie najlepszym narzÄ™dziem oferujÄ…cym dostÄ™p do Internetu oraz niespotykanie szybkie generowanie wynikÃ³w. Stworzenie wÅ‚asnego API pozwala jednak na znacznie wiÄ™kszÄ… personalizacjÄ™ oraz planowanie dziaÅ‚aÅ„ wykonywanych w tle (na przykÅ‚ad obserwowanie wybranych stron www).

### Hiper-personalizacja dziÄ™ki dÅ‚ugoterminowej pamiÄ™ci

W zwiÄ…zku z tym, Å¼e do kontekstu zapytania GPT-4 moÅ¼emy doÅ‚Ä…czyÄ‡ rÃ³Å¼ne informacje, naturalnym wydaje siÄ™ poÅ‚Ä…czenie ich z naszymi bazami wiedzy oraz rozmawianie z ich treÅ›ciÄ…. Kluczowym aspektem stajÄ… siÄ™ tutaj **organizacja oraz wyszukiwanie informacji**, ktÃ³re mogÄ… byÄ‡ dynamicznie wstrzykiwane do kontekstu i wykorzystane w trakcie generowania odpowiedzi.

ZÅ‚oÅ¼onoÅ›Ä‡ takich systemÃ³w roÅ›nie wraz z rozbudowÄ… bazy wiedzy. Jak juÅ¼ pokazaÅ‚em, umieszczenie w kontekÅ›cie zbyt wielu informacji lub ich bÅ‚Ä™dne dopasowanie negatywnie wpÅ‚ynie na zachowanie modelu i tym samym na wartoÅ›Ä‡ udzielonej odpowiedzi. PoniÅ¼sze pytanie o link do narzÄ™dzia podobnego do [Ray.so](http://ray.so/) sprawiÅ‚o, Å¼e przeszukana zostaÅ‚a baza zawierajÄ…ca **listÄ™ zasobÃ³w/linkÃ³w**. DziÄ™ki dopasowaniu sÅ‚Ã³w kluczowych oraz zastosowaniu bazy wektorowej i similarity search moÅ¼liwe byÅ‚o odnalezienie rekordu, ktÃ³ry najbardziej pasowaÅ‚ do przesÅ‚anego zapytania.

![](https://assets.circle.so/qaytsshufs6h80ygq2wl8xhth8mt)

MoÅ¼esz jednak uznaÄ‡, Å¼e takie wyszukiwanie moÅ¼e zostaÄ‡ zrealizowane prostym dopasowaniem sÅ‚Ã³w kluczowych i nie potrzebujemy tutaj AI. SytuacjÄ™ zmienia jednak kolejny przykÅ‚ad, w ktÃ³rym wyjaÅ›nienie cytatu zostaÅ‚o **zestawione z wiedzÄ… na mÃ³j temat**, czyniÄ…c wiadomoÅ›Ä‡ bardziej personalnÄ… i rezonujÄ…cÄ….

![](https://assets.circle.so/ufg0i8w49l8nbhjtbyhoy7gep5ak)

Interakcja z GPT-4, ktÃ³ry posiada dostÄ™p do wiedzy na nasz temat (na przykÅ‚ad na podstawie wczeÅ›niejszych interakcji), pokazuje prawdziwy potencjaÅ‚ tej technologii. Odpowiednio zaprojektowany system moÅ¼e nawet prowadziÄ‡ nas przez proces zdobywania konkretnych umiejÄ™tnoÅ›ci czy nawykÃ³w, opierajÄ…c siÄ™ na naszym dotychczasowym postÄ™pie.

### PoÅ‚Ä…czenie z usÅ‚ugami i urzÄ…dzeniami

Ostatnim z waÅ¼niejszych zastosowaÅ„ prywatnych jest poÅ‚Ä…czenie z rÃ³Å¼nymi usÅ‚ugami, na przykÅ‚ad listÄ… zadaÅ„, kalendarzem, aplikacjÄ… do notatek, pocztÄ… e-mail, komunikatorami czy wÅ‚asnymi skryptami realizujÄ…cymi rÃ³Å¼ne zadania. W rozmowie poniÅ¼ej rozpoznano **wydanie polecenia**, ktÃ³re nastÄ™pnie zostaÅ‚o skojarzone z **akcjÄ… dodawania zdarzeÅ„ do kalendarza**. W zwiÄ…zku z tym model wygenerowaÅ‚ obiekt JSON opisujÄ…cy wprowadzane zmiany oraz odpowiedÅº potwierdzajÄ…cÄ… wykonanie zadania.

![](https://assets.circle.so/atzypo5jpn38siju4ili0eg1rxdx)

WyposaÅ¼enie modeli jÄ™zykowych w narzÄ™dzia pozwala na zwiÄ™kszenie ich uÅ¼ytecznoÅ›ci oraz zredukowanie halucynacji. DoskonaÅ‚ym potwierdzeniem tych sÅ‚Ã³w jest [publikacja na temat ToolLM](https://arxiv.org/abs/2307.16789) â€” modelu wyspecjalizowanego w posÅ‚ugiwaniu siÄ™ API na podstawie dokumentacji.

Realizacja takich integracji jest moÅ¼liwa poprzez poÅ‚Ä…czenie wspomnianego juÅ¼ Function Calling oraz logiki aplikacji odpowiadajÄ…cej za faktyczne poÅ‚Ä…czenie z usÅ‚ugami lub urzÄ…dzeniami. Co ciekawe, w tym ostatnim obszarze, genialnie sprawdzajÄ… siÄ™ rozwiÄ…zania no-code/low-code, ktÃ³re pozwalajÄ… szybko iterowaÄ‡ oraz Å‚Ä…czyÄ‡ siÄ™ z rÃ³Å¼nymi usÅ‚ugami, [co szczegÃ³Å‚owo omawia ta publikacja](https://arxiv.org/abs/2304.08103).

## Praktyczne zastosowanie LLM w kontekÅ›cie zawodowym i biznesowym

DuÅ¼e Modele JÄ™zykowe sprawdzajÄ… siÄ™ nie tylko w wymiarze prywatnym, ale przede wszystkim biznesowym. NaleÅ¼y jednak nadal mieÄ‡ na uwadze fakt, Å¼e obecnie na rynku nie ma jeszcze dojrzaÅ‚ych narzÄ™dzi, frameworkÃ³w czy wzorcÃ³w projektowych pozwalajÄ…cych na swobodne rozwijanie aplikacji Å‚Ä…czÄ…cych kod z LLM. Doskonale obrazuje to slajd z prezentacji [State of GPT](https://youtu.be/bZQun8Y4L2A?t=2244), mÃ³wiÄ…cy m.in. o:

*   Wykorzystywaniu w **niekrytycznych** obszarach pod nadzorem czÅ‚owieka
    
*   Zastosowaniu jako ÅºrÃ³dÅ‚o inspiracji lub sugestii
    
*   Preferowaniu copilotÃ³w / asystentÃ³w niÅ¼ autonomicznych rozwiÄ…zaÅ„
    

![](https://assets.circle.so/s8n1w4ij71ytbvyul3d6ny4uj3e0)

  
MÃ³wiÄ…c o tym bardziej obrazowo, GPT-4 **nie jest jeszcze** **w peÅ‚ni gotowy** **do zastosowaÅ„ produkcyjnych** i obecnie sprawdzi siÄ™ jako ich **uzupeÅ‚nienie** lub do prywatnych zastosowaÅ„. GÅ‚Ã³wne argumenty, ktÃ³re potwierdzajÄ… takie nastawienie to:

*   Brak narzÄ™dzi do sterowania zachowaniem modelu, na ktÃ³rych moÅ¼na polegaÄ‡. WynikajÄ… z tego rÃ³Å¼nego rodzaju problemy, siÄ™gajÄ…ce nawet w obszar bezpieczeÅ„stwa, poniewaÅ¼ model moÅ¼e podejmowaÄ‡ dziaÅ‚ania niezgodne z zaÅ‚oÅ¼eniami. PrzykÅ‚adem moÅ¼e byÄ‡ wygenerowanie przez chatbota nieprawdziwej odpowiedzi.
    
*   DostÄ™pnoÅ›Ä‡ API nadal jest niewystarczajÄ…ca do biznesowych zastosowaÅ„ wymagajÄ…cych wysokiego SLA. Istnieje jednak opcja dostÄ™pu do modeli OpenAI w ramach Microsoft Azure lub poprzez [ChatGPT Enterprise](https://openai.com/blog/introducing-chatgpt-enterprise)
    

Sam posiadam rÃ³Å¼ne narzÄ™dzia wykorzystujÄ…ce modele OpenAI, ktÃ³re pomagajÄ… mi w pracy, ale absolutnie nie nadajÄ… siÄ™ do udostÄ™pnienia innym, nietechnicznym uÅ¼ytkownikom. Jako programista, dysponujÄ™ wiedzÄ… na temat pracy z modelami oraz w razie potrzeby mogÄ™ swobodnie wprowadzaÄ‡ potrzebne zmiany w promptach, oraz w kodzie. W przypadku produkcyjnych zastosowaÅ„ nie byÅ‚oby to juÅ¼ tak proste i przykÅ‚adowo, utrzymanie stabilnoÅ›ci aplikacji stanowiÅ‚oby doÅ›Ä‡ duÅ¼e wyzwanie (aczkolwiek, w praktyce zaleÅ¼y to od realizowanego projektu).

Naturalnie, **nie oznacza to, Å¼e zastosowanie GPT-4 w niektÃ³rych obszarach produkcyjnych nie jest moÅ¼liwe**. W praktyce jednak niemal wszystkie obecnie dostÄ™pne na rynku produkty, przy bliÅ¼szym poznaniu, okazujÄ… siÄ™ niedopracowane i, co gorsza, nie realizujÄ… oferowanej wartoÅ›ci. Ostatecznie, nie powinno stanowiÄ‡ to duÅ¼ego zaskoczenia, poniewaÅ¼ mÃ³wimy o zastosowaniu technologii, ktÃ³ra zaczÄ™Å‚a zdobywaÄ‡ popularnoÅ›Ä‡ kilkanaÅ›cie miesiÄ™cy temu. WiÄ™cej na temat zastosowaÅ„ produkcyjnych w kontekÅ›cie biznesowym powiemy w lekcjach zwiÄ…zanych z automatyzacjÄ… poÅ‚Ä…czonÄ… z AI oraz podczas projektowania wÅ‚asnego asystenta AI.

### AI oraz automatyzacja procesÃ³w, organizacja i dostÄ™p do wiedzy, rozwÃ³j produktÃ³w i ich funkcjonalnoÅ›ci

LLM majÄ… duÅ¼y potencjaÅ‚ w kontekÅ›cie zastosowania ich w obszarze automatyzacji procesÃ³w biznesowych oraz rozwoju produktÃ³w. W praktyce jednak bardzo **Å‚atwo jest zbudowaÄ‡ prototyp**, a dojÅ›cie do dziaÅ‚ajÄ…cego produktu zajmuje duÅ¼o czasu. Poza wymienionymi przed chwilÄ… wyzwaniami, wdroÅ¼enie rozwiÄ…zaÅ„ AI do istniejÄ…cych procesÃ³w wiÄ…Å¼e siÄ™ z podjÄ™ciem wymagajÄ…cych dziaÅ‚aÅ„. Mowa tutaj miÄ™dzy innymi o:

*   Poznaniu samej technologii przez zespÃ³Å‚. Zdobywanie wiedzy przez top-level management oraz osoby odpowiedzialne za faktyczne wdroÅ¼enie AI zajmuje czas. Obecnie na rynku brakuje wiedzy i jakoÅ›ciowych szkoleÅ„ kierowanych nie tylko dla programistÃ³w. Poza dostÄ™pnoÅ›ciÄ… wiedzy, do gry wchodzi jeszcze czas potrzebny na faktyczne zdobycie umiejÄ™tnoÅ›ci oraz pÃ³Åºniejsze praktyczne doÅ›wiadczenie.
    
*   Zazwyczaj wdroÅ¼enie rozwiÄ…zaÅ„ AI wymaga zgromadzenia i przetworzenia rÃ³Å¼nego rodzaju danych (bazy wiedzy, dokumentacje, opisy procesÃ³w, standardy itd.), co jest Å¼mudnym i czasochÅ‚onnym zajÄ™ciem. Zwykle wyzwanie stanowi tutaj **rozproszenie danych w rÃ³Å¼nych usÅ‚ugach oraz formatach**. Np. odczytanie danych z dokumentÃ³w PDF, nawet w poÅ‚Ä…czeniu z AI, nie jest proste. Po zgromadzeniu danych konieczne jest ich przetworzenie i przygotowanie na potrzeby modeli jÄ™zykowych (kategoryzacja, tagowanie, wzbogacanie, dzielenie na mniejsze fragmenty) w sposÃ³b umoÅ¼liwiajÄ…cy ich aktualizacjÄ™. Nierzadko mÃ³wi siÄ™, Å¼e wdroÅ¼enie AI to przede wszystkim praca zwiÄ…zana z organizacjÄ…Â danych.
    
*   JuÅ¼Â na etapie developmentu pojawiajÄ…Â siÄ™Â wyzwania zwiÄ…zane z kosztami usÅ‚ug dostawcÃ³w zarÃ³wno modeli (np. OpenAI), jak i zewnÄ™trznych API (np. Qdrant). Rozliczanie w modelu uzaleÅ¼nionym od zuÅ¼ycia generuje dodatkowe koszty dla kaÅ¼dej osoby zaangaÅ¼owanej w development. Optymalizacja zajmuje czas i wymaga wiedzy zwiÄ…zanej nie tylko z projektowaniem promptÃ³w, ale takÅ¼e optymalizacji mechanizmÃ³w wyszukiwania czy przetwarzania treÅ›ci.
    
*   Aplikacja dziaÅ‚ajÄ…ca na produkcji wymaga staÅ‚ego monitorowania oraz podjÄ™cia dodatkowych krokÃ³w zwiÄ…zanych z moderowaniem danych wejÅ›ciowych pod kÄ…tem zgodnoÅ›ci np. z politykÄ…Â openai, oraz zaÅ‚oÅ¼eniami naszego oprogramowania (np. nie chcemy, aby czatbot przyjmujÄ…cy zamÃ³wienia byÅ‚ w stanie rozmawiaÄ‡ na inne tematy). Do tego dochodzi takÅ¼e moÅ¼liwoÅ›Ä‡ minimalizowania ryzyka wygenerowania niepoprawnych odpowiedzi (halucynacji modelu) oraz obsÅ‚uga bÅ‚Ä™dÃ³w i przypadkÃ³w brzegowych.
    
*   RozwÃ³j aplikacji wykorzystujÄ…cych LLM generuje takÅ¼e problemy w zwiÄ…zku z wprowadzaniem modyfikacji i budowaniem nowych funkcjonalnoÅ›ci. W przeciwieÅ„stwie do kodu nie mamy tutaj jeszcze sensownych narzÄ™dzi umoÅ¼liwiajÄ…cych testowanie promptÃ³w w celu upewnienia siÄ™, Å¼e aktualizacja nie wprowadza regresji w aplikacji. Problem ten zaczyna byÄ‡ adresowany poprzez narzÄ™dzia takie jak [LangSmith](https://smith.langchain.com/) (jest jeszcze na bardzo wczesnym etapie rozwoju).
    

Podstawowe ÅºrÃ³dÅ‚a na temat zastosowaÅ„ produkcyjnych moÅ¼na znaleÅºÄ‡ [w dokumentacji OpenAI](https://platform.openai.com/docs/guides/safety-best-practices). Jest to jednak wierzchoÅ‚ek gÃ³ry lodowej, dlatego w miarÄ™ moÅ¼liwoÅ›ci podzielÄ™ siÄ™ wÅ‚asnymi doÅ›wiadczeniami "z produkcji" na przestrzeni caÅ‚ego kursu AI\_Devs. ChciaÅ‚bym jednak podkreÅ›liÄ‡, Å¼e nie na wszystkie pytania mamy odpowiedzi (nie tylko jako twÃ³rcy kursu, ale nawet OpenAI nie ma rozwiÄ…zaÅ„ np. na prompt injection).

PowyÅ¼sze punkty mogÄ… pozostawiÄ‡ CiÄ™ z wraÅ¼eniem, Å¼e jakiekolwiek zastosowanie LLM w kodzie produkcyjnym jest niemoÅ¼liwe. Nie jest to prawda i z powodzeniem LLM sprawdzÄ…Â siÄ™Â do:

*   ZastosowaÅ„ wewnÄ™trznych, np. narzÄ™dzi obsÅ‚ugiwanych przez osoby posiadajÄ…ce wiedzÄ™ na temat pracy z nimi.
    
*   Systemach ograniczajÄ…cych dowolnoÅ›Ä‡ wprowadzanych danych i sposobu prezentowania odpowiedzi. CzÄ™sto wiÄ…Å¼e siÄ™ to z zastosowaniem AI "w tle". PrzykÅ‚adem moÅ¼e byÄ‡ przycisk "dopasuj kolor z AI", ktÃ³ry przeanalizuje obraz i wygeneruje dla niego paletÄ™ kolorÃ³w zgodnie ze zdefiniowanÄ… instrukcjÄ….
    
*   FunkcjonalnoÅ›ciach stanowiÄ…cych wsparcie, niepeÅ‚niÄ…cych krytycznej roli oraz realizujÄ…cych jasno zdefiniowany proces, ktÃ³ry Å‚atwo monitorowaÄ‡. PrzykÅ‚adem moÅ¼e byÄ‡ wzbogacanie bÄ…dÅº klasyfikowanie treÅ›ci lub zaawansowane mechanizmy sugerujÄ…ce treÅ›ci na podstawie dopasowaÅ„ niemoÅ¼liwych (bÄ…dÅº trudnych) do zrealizowania z pomocÄ… kodu.
    
*   WdroÅ¼eniach uwzglÄ™dniajÄ…cych trenowanie i/lub fine-tuning modeli, w celu wyspecjalizowania ich w bardzo konkretnych zadaniach.
    

Ostatecznie nikt nie zabrania peÅ‚nego, produkcyjnego zastosowania LLM. Scenariusze zarysowane powyÅ¼ej moÅ¼na do pewnego stopnia adresowaÄ‡ lub zgodziÄ‡ siÄ™ na kompromisy. Tym bardziej Å¼e wiele problemÃ³w, ktÃ³re widzimy dzisiaj, niebawem mogÄ… caÅ‚kowicie zniknÄ…Ä‡. PrzykÅ‚adem moÅ¼e byÄ‡ kwestia prywatnoÅ›ci danych, ktÃ³rÄ… teraz moÅ¼na zaadresowaÄ‡ poprzez plany Enterprise czy modele Open Source. Zamiast czekaÄ‡ na gotowe rozwiÄ…zania, moÅ¼na juÅ¼ teraz zdobywaÄ‡ doÅ›wiadczenie, ktÃ³re okaÅ¼e siÄ™ przydatne w przyszÅ‚oÅ›ci.

* * *

## Zadania praktyczne

  

> **WaÅ¼ne:** Upewnij siÄ™, Å¼e jesteÅ›Â zalogowany / zalogowana na swoje konto easy\_. JeÅ›li nie posiadasz hasÅ‚a, skorzystaj z opcji resetowania dostÄ™pnej Â» [tutaj](https://id.easy.tools/?callback=easycart&lang=pl) Â« dla e-maila na ktÃ³ry masz utworzone konto na platformie [http://bravecourses.circle.so](http://bravecourses.circle.so/).

1.  Zapoznaj siÄ™ z naszym systemem do zadaÅ„ manualnych. BÄ™dzie on wykorzystywany w kolejnych lekcjach. DziÅ› otrzymujesz zadanie na rozgrzewkÄ™. Nie jest to atak typu prompt injection, a zwykÅ‚e Ä‡wiczenie polegajÄ…ce na odpytywaniu o jawne informacje. [https://tasks.aidevs.pl/chat/getinfo](https://tasks.aidevs.pl/chat/getinfo)
    
2.  Do wybranych lekcji doÅ‚Ä…czymy praktyczne zadania, ktÃ³rych sprawdzanie odbÄ™dzie siÄ™ w sposÃ³b automatyczny. **Nie wyklucza to jednak moÅ¼liwoÅ›ci zadawania pytaÅ„Â w komentarzach.** System weryfikacji zadaÅ„Â skÅ‚ada siÄ™ z dwÃ³ch czÄ™Å›ci: **API** oraz **Playground.**
    

  

Komunikacja z API odbywa siÄ™Â z pomocÄ… kodu oraz formatu JSON, a kaÅ¼de z zadaÅ„Â skÅ‚ada siÄ™ z trzech czÄ™Å›ci:

*   autoryzacji
    
*   pobierania danych wejÅ›ciowych (string lub tablica obiektÃ³w)
    
*   odesÅ‚ania odpowiedzi (wÅ‚aÅ›ciwoÅ›Ä‡ **answer)**
    

![](https://assets.circle.so/0x9ljh37u5ine6l08phevpvfbv14)

  

> ğŸ”¥ Uwaga: serwer przy kaÅ¼dorazowym pobraniu zadania domowego moÅ¼e wygenerowaÄ‡ dla Ciebie nowe dane wejÅ›ciowe. Nie zakÅ‚adaj wiÄ™c, Å¼e raz pobrane dane sÄ… Twoje na zawsze i moÅ¼esz teraz opracowaÄ‡Â dla nich rozwiÄ…zanie. Twoim zadaniem jest opracowanie algorytmu, ktÃ³ry zwraca poprawne wyniki dla kaÅ¼dego zestawu pobranych danych.

  

**ğŸ’¡ Sugestia**

Na potrzeby rozwiÄ…zywania zadaÅ„, napisz trzy funkcje wykonujÄ…ce kolejno: autoryzacjÄ™, pobieranie treÅ›ci zadania oraz wysyÅ‚anie odpowiedzi. Te akcje bÄ™dziesz wykonywaÄ‡ w przypadku kaÅ¼dego zadania, wiÄ™c to dobry sposÃ³b na optymalizacjÄ™ czasu. Wybierz technologiÄ™, w ktÃ³rej czujesz siÄ™Â swobodnie. MoÅ¼e to byÄ‡ takÅ¼e scenariusz [make.com](http://make.com/).

Druga czÄ™Å›Ä‡ systemu to Playground, ktÃ³ra dziaÅ‚aniem i wyglÄ…dem przypomina Playground z platformy OpenAI. Jednak w przeciwieÅ„stwie do niego, nasza wersja czasem posiada zablokowane pola. Twoim zadaniem jest zmodyfikowanie dostÄ™pnych pÃ³l, aby osiÄ…gnÄ…Ä‡ zaÅ‚oÅ¼ony w zadaniu cel. Tych rozwiÄ…zaÅ„Â nie musisz automatyzowaÄ‡ i moÅ¼esz wykonaÄ‡ je rÄ™cznie.

Na poczÄ…tek dostaniesz dwa zadania startowe:

*   Przygotuj prostÄ… aplikacjÄ™/skrypt do zaliczenia zadania 'helloapi'
    
*   SprÃ³buj sprytnie zagadaÄ‡Â do ChatGPT w poniÅ¼szym zadaniu: [https://tasks.aidevs.pl/chat/getinfo](https://tasks.aidevs.pl/chat/getinfo)
    

Zapoznaj siÄ™ z poniÅ¼szym filmem, aby lepiej zrozumieÄ‡, jak dziaÅ‚a automat sprawdzajÄ…cy zadania zarÃ³wno pod wzglÄ™dem API, jak i Playgorund.

[tasks\_aidevs\_instrukcja.mp4](https://assets.circle.so/t6q82g5z0uvw0fj49c2zcl0p1t2t)